{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "scrolled": false
      },
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install pandas\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Requirement already satisfied: nltk in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (3.3)\nRequirement already satisfied: six in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from nltk) (1.11.0)\n\u001b[33mWARNING: You are using pip version 19.1.1, however version 19.2.2 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: pandas in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (0.23.4)\nRequirement already satisfied: python-dateutil>=2.5.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from pandas) (2.8.0)\nRequirement already satisfied: pytz>=2011k in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from pandas) (2018.7)\nRequirement already satisfied: numpy>=1.9.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from pandas) (1.16.2)\nRequirement already satisfied: six>=1.5 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas) (1.11.0)\n\u001b[33mWARNING: You are using pip version 19.1.1, however version 19.2.2 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "# Utility"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Here we create methods for future use"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import csv\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "resourceFolder = 'resources'\n",
        "outputFolder = 'output'\n",
        "\n",
        "\n",
        "def getResourceFolderPath(fileName) : \n",
        "    return  os.path.join(os.path.join(os.getcwd(), resourceFolder), fileName)\n",
        "def getOutputFolderPath(folder, fileName) : \n",
        "    return  os.path.join(os.path.join(os.path.join(os.getcwd(), outputFolder), folder), fileName)\n",
        "\n",
        "def loadCSVData(path):\n",
        "    return pd.read_csv(getResourceFolderPath(path), encoding=\"utf-8\")\n",
        "\n",
        "def loadTxtData(path, sep, columns, encoding = \"utf-8\"):\n",
        "    result = pd.read_csv(getResourceFolderPath(path), sep, header=None, engine='python', encoding= encoding)\n",
        "    result.columns = columns\n",
        "    return result\n",
        "\n",
        "def getFullPath(folder, file):\n",
        "    if not os.path.exists(outputFolder):\n",
        "        os.mkdir(outputFolder)\n",
        "    folder = os.path.join(outputFolder, folder)\n",
        "    if not os.path.exists(folder):\n",
        "        os.mkdir(folder)\n",
        "    return os.path.join(folder, file)    \n",
        "\n",
        "def writeCSV(folder,file, list):\n",
        "    with open(getFullPath(folder, file), \"w\", newline=\"\", encoding='utf-8') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerows(list)\n",
        "\n",
        "def writeDFCSV(folder,file, dataframe):\n",
        "    dataframe.to_csv(getFullPath(folder, file))\n",
        "    \n",
        "    "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "nltk.download('punkt')\n",
        "\n",
        "#clear the given text using regex \n",
        "def cleanText(text):\n",
        "    stripped = text.strip()\n",
        "    PATTERN = r'[,|.|?|$|#|!|&|*|%|@|(|)|~|^0-9]'\n",
        "    result = re.sub(PATTERN, r'', stripped)\n",
        "    return result.lower().replace('\"', '') \n",
        "\n",
        "# create a list of tokens for for the given text \n",
        "def tokenize(text):\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    wordTokens = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
        "    return wordTokens\n",
        "\n",
        "# clear the text after tokenization\n",
        "def cleanAftertokenization(tokens):\n",
        "    pattern = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
        "    filteredTokens =  filter(None, [pattern.sub('', token) for token in tokens])\n",
        "    return [token for token in tokens if pattern.sub('', token) != None]\n",
        "\n",
        "\n",
        "# check if given string is english \n",
        "# we use encoding methods to identify if it passes anexception we it will be a sinhala text \n",
        "def isWordEnglish(s):\n",
        "    try:\n",
        "        s.encode(encoding='utf-8').decode('ascii')\n",
        "    except UnicodeDecodeError:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "# retrun the word if it matches the passed lanaguage else none \n",
        "def checkGetWordByLanguage(word,isEnglish):\n",
        "    if (isEnglish and isWordEnglish(word) or ((not isEnglish) and (not isWordEnglish(word)))):\n",
        "        return word\n",
        "    else :\n",
        "        return None\n",
        "\n",
        "# create a list for the given language\n",
        "def createLanguageSeparatedList(list,isEnglish):\n",
        "    # select only sinhala words\n",
        "    return [text for text in list if checkGetWordByLanguage(text, isEnglish) != None]\n",
        "\n",
        "# results for part 1 \n",
        "def part1result(outputResult = False):\n",
        "    # load the data \n",
        "    data = loadCSVData('Sinhala_Singlish_Hate_Speech.csv')\n",
        "    #clear \n",
        "    data[\"CleanedPhrase\"] = data[\"Phrase\"].apply(cleanText)\n",
        "    # tokenize\n",
        "    data[\"TokenFullList\"] = data[\"CleanedPhrase\"].apply(tokenize)\n",
        "    # convert to a single list\n",
        "    data[\"SingleList\"] = [fullsentence for line in data[\"TokenFullList\"] for fullsentence in line]\n",
        "    #final tokens \n",
        "    data[\"Tokens\"] = data[\"SingleList\"].apply(cleanAftertokenization)\n",
        "    # sinhala only token list \n",
        "    data[\"SinhalaTokens\"] = [createLanguageSeparatedList(tokens, False) for tokens in data[\"Tokens\"] ]\n",
        "    # english/singli\n",
        "    data[\"EnglishTokens\"] = [createLanguageSeparatedList(tokens, True) for tokens in data[\"Tokens\"] ]\n",
        "    # calculate the percentages\n",
        "    data[\"SinhalaTokenPercentage\"] = data.apply(lambda row: (len(row.SinhalaTokens) / len(row.Tokens)) * 100, axis=1)\n",
        "    data[\"EnglishTokenPercentage\"] = data.apply(lambda row: (len(row.EnglishTokens) / len(row.Tokens)) * 100, axis=1)\n",
        "    \n",
        "    # need to do  spelling\n",
        "    \n",
        "    # print as csv\n",
        "    if(outputResult):\n",
        "        writeDFCSV(\"part1\", \"result.csv\", data)\n",
        "        writeCSV(\"part1\", \"sinhala-word-list.csv\", data[\"SinhalaTokens\"].tolist())\n",
        "        writeCSV(\"part1\", \"english-word-list.csv\", data[\"EnglishTokens\"].tolist())\n",
        "    return data\n",
        "\n",
        "data = part1result(False)\n",
        "\n",
        "print(data.head())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[nltk_data] Downloading package punkt to /home/nbuser/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n   PhraseNo                                             Phrase IsHateSpeech  \\\n0         1  මේ බැල්ලි කොටින්ගේ ගු කනකොට අපහසුවක් දැනුනෙ නැ...          YES   \n1         2  මන් ඊයේ මුස්ලිම් ඩෑල් එකක් එක්ක සෙල්ෆියක් ගත්ත...          YES   \n2         3                           සංහිදියාවට අවුලක් වෙයි ද           NO   \n3         4  .කටින් පුරසාරම් දොඩන අපි සිංහලයො විදියට ලැජ්ජා...          YES   \n4         5  මචන් ඔය මගුල නවත්තලා කොන්දක් තියෙනවානම් පුලුවන...          YES   \n\n                                       CleanedPhrase  \\\n0  මේ බැල්ලි කොටින්ගේ ගු කනකොට අපහසුවක් දැනුනෙ නැ...   \n1  මන් ඊයේ මුස්ලිම් ඩෑල් එකක් එක්ක සෙල්ෆියක් ගත්ත...   \n2                           සංහිදියාවට අවුලක් වෙයි ද   \n3  කටින් පුරසාරම් දොඩන අපි සිංහලයො විදියට ලැජ්ජා ...   \n4  මචන් ඔය මගුල නවත්තලා කොන්දක් තියෙනවානම් පුලුවන...   \n\n                                       TokenFullList  \\\n0  [[මේ, බැල්ලි, කොටින්ගේ, ගු, කනකොට, අපහසුවක්, ද...   \n1  [[මන්, ඊයේ, මුස්ලිම්, ඩෑල්, එකක්, එක්ක, සෙල්ෆි...   \n2                    [[සංහිදියාවට, අවුලක්, වෙයි, ද]]   \n3  [[කටින්, පුරසාරම්, දොඩන, අපි, සිංහලයො, විදියට,...   \n4  [[මචන්, ඔය, මගුල, නවත්තලා, කොන්දක්, තියෙනවානම්...   \n\n                                          SingleList  \\\n0  [මේ, බැල්ලි, කොටින්ගේ, ගු, කනකොට, අපහසුවක්, දැ...   \n1  [මන්, ඊයේ, මුස්ලිම්, ඩෑල්, එකක්, එක්ක, සෙල්ෆිය...   \n2                      [සංහිදියාවට, අවුලක්, වෙයි, ද]   \n3  [කටින්, පුරසාරම්, දොඩන, අපි, සිංහලයො, විදියට, ...   \n4  [මචන්, ඔය, මගුල, නවත්තලා, කොන්දක්, තියෙනවානම්,...   \n\n                                              Tokens  \\\n0  [මේ, බැල්ලි, කොටින්ගේ, ගු, කනකොට, අපහසුවක්, දැ...   \n1  [මන්, ඊයේ, මුස්ලිම්, ඩෑල්, එකක්, එක්ක, සෙල්ෆිය...   \n2                      [සංහිදියාවට, අවුලක්, වෙයි, ද]   \n3  [කටින්, පුරසාරම්, දොඩන, අපි, සිංහලයො, විදියට, ...   \n4  [මචන්, ඔය, මගුල, නවත්තලා, කොන්දක්, තියෙනවානම්,...   \n\n                                       SinhalaTokens EnglishTokens  \\\n0  [මේ, බැල්ලි, කොටින්ගේ, ගු, කනකොට, අපහසුවක්, දැ...            []   \n1  [මන්, ඊයේ, මුස්ලිම්, ඩෑල්, එකක්, එක්ක, සෙල්ෆිය...            []   \n2                      [සංහිදියාවට, අවුලක්, වෙයි, ද]            []   \n3  [කටින්, පුරසාරම්, දොඩන, අපි, සිංහලයො, විදියට, ...            []   \n4  [මචන්, ඔය, මගුල, නවත්තලා, කොන්දක්, තියෙනවානම්,...            []   \n\n   SinhalaTokenPercentage  EnglishTokenPercentage  \n0                   100.0                     0.0  \n1                   100.0                     0.0  \n2                   100.0                     0.0  \n3                   100.0                     0.0  \n4                   100.0                     0.0  \n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# removes stop words in the list using the passed stop word list \n",
        "def removeStopwords(stopwords, tokens):\n",
        "    return [token for token in tokens if token not in stopwords]\n",
        "\n",
        "# updates stem words according to passed stem list and returns the list of tokens \n",
        "def updateToStem(stemWordList, tokens):\n",
        "    result = []\n",
        "    for token in tokens:\n",
        "        row = stemWordList[stemWordList[\"word\"] == token]\n",
        "        if not row.empty :\n",
        "            result.append(row[\"stem\"].values.tolist()[0])\n",
        "        else :\n",
        "            result.append(token)\n",
        "    return result\n",
        "\n",
        "def part2result(data, outputResult = False):\n",
        "    # load stop words \n",
        "    stopwords = loadTxtData('StopWords.txt', '\\t', ['stopword', 'number'], \"utf16\")\n",
        "    # load stem words\n",
        "    stemwords = loadTxtData('stem_dictionary.txt', '\\t', ['word', 'stem'])\n",
        "    # create list after stop word removal\n",
        "    data[\"AfterStopWord\"] = [removeStopwords(stopwords[\"stopword\"].values.tolist(), tokenList) for tokenList in data[\"Tokens\"]]\n",
        "    # create list after stemming \n",
        "    data[\"FullTokens\"] = [updateToStem(stemwords, tokenList) for tokenList in data[\"AfterStopWord\"]]\n",
        "    # sinhala only token list \n",
        "    data[\"FullSinhalaTokens\"] = [createLanguageSeparatedList(tokens, False) for tokens in data[\"FullTokens\"] ]\n",
        "    # english/singlish token list \n",
        "    data[\"FullEnglishTokens\"] = [createLanguageSeparatedList(tokens, True) for tokens in data[\"FullTokens\"] ]\n",
        "    \n",
        "    # clean up the data set \n",
        "    data = data[['FullTokens', 'FullSinhalaTokens', 'FullEnglishTokens', 'IsHateSpeech']].copy()\n",
        "    \n",
        "    # print as csv\n",
        "    if(outputResult):\n",
        "        writeDFCSV(\"part2\", \"result.csv\", data)\n",
        "    return data\n",
        "\n",
        "data = part2result(data, True)\n",
        "\n",
        "\n",
        "print(data.head())\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "                                          FullTokens  \\\n0  [බැල්ලි, කොටින්, ගු, කනකොට, අපහසුවක්, දැනුනෙ, ...   \n1  [මන්, ඊයේ, මුස්ලිම්, ඩෑල්, එකක්, සෙල්ෆි, ගත්තා...   \n2                             [සංහිදියා, අවුල, වෙයි]   \n3  [කටින්, පුරසාරම්, දොඩන, අපි, සිංහලයො, විදියට, ...   \n4  [මචන්, මගුල, නවත්තල, කොන්ද, තියෙනවානම්, පුලුවන...   \n\n                                   FullSinhalaTokens FullEnglishTokens  \\\n0  [බැල්ලි, කොටින්, ගු, කනකොට, අපහසුවක්, දැනුනෙ, ...                []   \n1  [මන්, ඊයේ, මුස්ලිම්, ඩෑල්, එකක්, සෙල්ෆි, ගත්තා...                []   \n2                             [සංහිදියා, අවුල, වෙයි]                []   \n3  [කටින්, පුරසාරම්, දොඩන, අපි, සිංහලයො, විදියට, ...                []   \n4  [මචන්, මගුල, නවත්තල, කොන්ද, තියෙනවානම්, පුලුවන...                []   \n\n  IsHateSpeech  \n0          YES  \n1          YES  \n2           NO  \n3          YES  \n4          YES  \n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": [
        "## Part 2 Results "
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "# Part 3"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gensim\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "import re\n",
        "    \n",
        "warnings.filterwarnings('ignore')\n",
        "    \n",
        "#first we divide to train and test data sets \n",
        "\n",
        "def prepare_datasets(corpus, labels, test_data_proportion=0.2):\n",
        "    train_X, test_X, train_Y, test_Y = train_test_split(corpus, labels, \n",
        "                                                        test_size=test_data_proportion, random_state=42)\n",
        "    return train_X, test_X, train_Y, test_Y\n",
        "\n",
        "\n",
        "# First we do feature extraction using Courter Vectorizer\n",
        "\n",
        "def bow_extractor(corpus, ngram_range=(1,1)):\n",
        "    vectorizer = CountVectorizer(min_df=1, ngram_range=ngram_range)\n",
        "    features = vectorizer.fit_transform(corpus)\n",
        "    return vectorizer, features\n",
        "\n",
        "\n",
        "def get_metrics(true_labels, predicted_labels):\n",
        "    \n",
        "    print('Accuracy:', np.round(\n",
        "                        metrics.accuracy_score(true_labels, \n",
        "                                               predicted_labels),\n",
        "                        2))\n",
        "    print('Precision:', np.round(\n",
        "                        metrics.precision_score(true_labels, \n",
        "                                               predicted_labels,\n",
        "                                               average='weighted'),\n",
        "                        2))\n",
        "    print('Recall:', np.round(\n",
        "                        metrics.recall_score(true_labels, \n",
        "                                               predicted_labels,\n",
        "                                               average='weighted'),\n",
        "                        2))\n",
        "    print('F1 Score:', np.round(\n",
        "                        metrics.f1_score(true_labels, \n",
        "                                               predicted_labels,\n",
        "                                               average='weighted'),\n",
        "                        2))\n",
        "                        \n",
        "\n",
        "def train_predict_evaluate_model(classifier, \n",
        "                                 train_features, train_labels, \n",
        "                                 test_features, test_labels, text):\n",
        "    # build model    \n",
        "    classifier.fit(train_features, train_labels)\n",
        "    # predict using model\n",
        "    predictions = classifier.predict(test_features) \n",
        "    # evaluate model prediction performance \n",
        "    print(\"------------------------Model metrice for {}------------------------\".format(text))\n",
        "    get_metrics(true_labels=test_labels, \n",
        "                predicted_labels=predictions)\n",
        "    return predictions \n",
        "\n",
        "def getConfussionMatrix(test_labels, prediction, description):\n",
        "    cm = metrics.confusion_matrix(test_labels, prediction)\n",
        "    pd.DataFrame(cm, index=range(0,2), columns=range(0,2))\n",
        "    \n",
        "    print(\"------------------------Confussion metrice for {}------------------------\".format(description))\n",
        "    \n",
        "    print(\"                     Prediction    \")\n",
        "    print(\"                 P     |    N   \")\n",
        "    print(\"              ---------|---------\")\n",
        "    print(\"               P {0}       {1}   \".format(cm[0][0], cm[0][1]))\n",
        "    print(\"    Actual   ----------|---------\")\n",
        "    print(\"               N {0}       {1}   \".format(cm[1][0], cm[1][1]))    \n",
        "    print(\"                       | \") \n",
        "    \n",
        "    return cm\n",
        "\n",
        "def getCoeeffienct(classiffier, vectorizer, description):\n",
        "    print(\"------------------------Most important words the model for {}  ------------------------\".format(description))\n",
        "    #get the indexes of the maximum 20 coef_ values\n",
        "    max_coef_indexes = classiffier.coef_[0].argsort()[::-1][:20]\n",
        "    \n",
        "    for index in max_coef_indexes:\n",
        "        print(\"   \" + vectorizer.get_feature_names()[index])\n",
        "\n",
        "    # Checking the misclassified documents for error analysis\n",
        "def checkForMisclassified(test_corpus, test_labels, predictor):\n",
        "    num = 0\n",
        "    for document, label, predicted_label in zip(test_corpus, test_labels, predictor):        \n",
        "        if label != predicted_label:\n",
        "            print('Actual Label:', label)\n",
        "            print('Predicted Label:', predicted_label)\n",
        "            print('Document:-')\n",
        "            print(re.sub('\\n', ' ', document))\n",
        "            print()\n",
        "            num += 1\n",
        "            if num == 4:\n",
        "                break\n",
        "                \n",
        "    \n",
        "                \n",
        "def predict(dataframe, corpusText, labelText, splitPercentage, classiffier, description):\n",
        "    # differentiate the data for train and test sets \n",
        "    train_corpus, test_corpus, train_labels, test_labels = prepare_datasets(dataframe[corpusText],\n",
        "                                                                                dataframe[labelText],\n",
        "                                                                                test_data_proportion=splitPercentage)\n",
        "    # bag of words transformation \n",
        "    bow_vectorizer, bow_train_features = bow_extractor(train_corpus)  \n",
        "    bow_test_features = bow_vectorizer.transform(test_corpus)\n",
        "    \n",
        "    bow_predictions = train_predict_evaluate_model(classifier=classiffier,\n",
        "                                                       train_features=bow_train_features,\n",
        "                                                       train_labels=train_labels,\n",
        "                                                       test_features=bow_test_features,\n",
        "                                                       test_labels=test_labels,\n",
        "                                                        text = description)\n",
        "    \n",
        "    # Confusion matrix for the CV based SVM\n",
        "    cm = getConfussionMatrix(test_labels, bow_predictions, description)\n",
        "    \n",
        "    \n",
        "    getCoeeffienct(classiffier, bow_vectorizer, description)\n",
        "    \n",
        "    #print(\"------------------------Mis classified records sample {}------------------------\".format(description))\n",
        "    #checkForMisclassified(test_corpus, test_labels, bow_predictions)\n",
        "    \n",
        "\n",
        "def part3Result(data):\n",
        "    \n",
        "    # create separate dataframes with only sinhala or singlsih content data \n",
        "    data[\"SinhalaFullTokenCount\"] = data.apply(lambda row: len(row.FullSinhalaTokens), axis=1)\n",
        "    data[\"EnglishFullTokenCount\"] = data.apply(lambda row: len(row.FullEnglishTokens), axis=1)\n",
        "    sinhala_corpus = data[data.SinhalaFullTokenCount > 0]\n",
        "    singlish_corpus = data[data.EnglishFullTokenCount > 0]\n",
        "    sinhala_corpus[\"FullText\"] = data.apply(lambda row: ' '.join(row.FullSinhalaTokens), axis=1)\n",
        "    singlish_corpus[\"FullText\"] = data.apply(lambda row: ' '.join(row.FullEnglishTokens), axis=1)\n",
        "    \n",
        "    #predict for sinhala only data set \n",
        "    svm = SGDClassifier(loss='hinge', n_iter=100)\n",
        "    predict(sinhala_corpus, \"FullText\", \"IsHateSpeech\", 0.2, svm, \"Sinhala only data set\")\n",
        "    \n",
        "    #predict for singlish only data set \n",
        "    svm = SGDClassifier(loss='hinge', n_iter=100)\n",
        "    predict(singlish_corpus, \"FullText\", \"IsHateSpeech\", 0.2, svm, \"Singlish only data set\")\n",
        "    \n",
        "part3Result(data)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "------------------------Model metrice for Sinhala only data set------------------------\nAccuracy: 0.65\nPrecision: 0.65\nRecall: 0.65\nF1 Score: 0.65\n------------------------Confussion metrice for Sinhala only data set------------------------\n                     Prediction    \n                 P     |    N   \n              ---------|---------\n               P 140       53   \n    Actual   ----------|---------\n               N 72       97   \n                       | \n------------------------Most important words the model for Sinhala only data set  ------------------------\n   ජම\n   ඉග\n   මරල\n   ඇම\n   පකය\n   ආන\n   සමනල\n   පලයව\n   රව\n   බණට\n   කහන\n   කවලවම\n   ජනප\n   ඇර\n   බළ\n   එර\n   දඬ\n   රඟප\n   ගහපන\n   ගහ\n------------------------Model metrice for Singlish only data set------------------------\nAccuracy: 0.66\nPrecision: 0.67\nRecall: 0.66\nF1 Score: 0.67\n------------------------Confussion metrice for Singlish only data set------------------------\n                     Prediction    \n                 P     |    N   \n              ---------|---------\n               P 85       40   \n    Actual   ----------|---------\n               N 32       57   \n                       | \n------------------------Most important words the model for Singlish only data set  ------------------------\n   fity\n   channel\n   noize\n   twitter\n   clip\n   ekak\n   help\n   unp\n   set\n   suppper\n   head\n   wedding\n   tika\n   yako\n   danna\n   munta\n   gon\n   admin\n   plan\n   fb\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": [
        "### Part D\n",
        "\n",
        "1. Repeat step (c) treating the full data set (Sinhala and ‘Singlish’) as one and compare the results with (c)."
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "def partDResult(data):\n",
        "    \n",
        "    # create separate dataframes with only sinhala or singlsih content data \n",
        "    data[\"FullText\"] = data.apply(lambda row: ' '.join(row.FullTokens), axis=1)\n",
        "    \n",
        "    #predict for sinhala only data set \n",
        "    svm = SGDClassifier(loss='hinge', n_iter=100)\n",
        "    predict(data, \"FullText\", \"IsHateSpeech\", 0.2, svm, \"Full data set\")\n",
        "    \n",
        "partDResult(data)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "------------------------Model metrice for Full data set------------------------\nAccuracy: 0.66\nPrecision: 0.66\nRecall: 0.66\nF1 Score: 0.65\n------------------------Confussion metrice for Full data set------------------------\n                     Prediction    \n                 P     |    N   \n              ---------|---------\n               P 212       60   \n    Actual   ----------|---------\n               N 110       118   \n                       | \n------------------------Most important words the model for Full data set  ------------------------\n   ජම\n   අගම\n   මරල\n   ලකණ\n   පකය\n   පලයව\n   නමට\n   මමද\n   ලකන\n   ආන\n   රව\n   මචන\n   කහන\n   කනව\n   මස\n   බණට\n   තරල\n   රවන\n   ජර\n   ගහපන\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "### Part D\n",
        "\n",
        "2. Based on your results, decide whether to process these two data sets together or separately for the following tasks.\n",
        "\n",
        "*Based on the above results combining and running it gives better results compared to separated corpuses*"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "### Part E\n",
        "\n",
        "1. Implement a logistic regression model to the dataset after transforming it to their tf-idf values4. \n",
        "2. In order to test the stability of the predictive power of this model, this time compute the cross-validation scores for accuracy, precision, recall and f1 score for it. \n",
        "3. Also check the most important words the model uses to discriminate between relevant and irrelevant words as before."
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# Insert #represent the tokens in a count vector\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from functools import partial\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, make_scorer\n",
        "\n",
        "\n",
        "def tfidf_extractor(corpus, ngram_range=(1,1)):\n",
        "    \n",
        "    vectorizer = TfidfVectorizer(min_df=1, \n",
        "                                 norm='l2',\n",
        "                                 smooth_idf=True,\n",
        "                                 use_idf=True,\n",
        "                                 ngram_range=ngram_range)\n",
        "    features = vectorizer.fit_transform(corpus)\n",
        "    return vectorizer, features\n",
        "\n",
        "\n",
        "#printing the measurements for cross validation for 5 flods\n",
        "def print_cross_validation_model_measurements(model, data_test, label_test):       \n",
        "    \n",
        "    #https://stackoverflow.com/a/39197222\n",
        "    #https://github.com/scikit-learn/scikit-learn/issues/3570\n",
        "    precision_scorer = make_scorer(precision_score, pos_label='YES')\n",
        "    recall_scorer = make_scorer(recall_score, pos_label='YES')\n",
        "    f1_scorer = make_scorer(f1_score, pos_label='YES')\n",
        "    \n",
        "    acuuracy = cross_val_score(model, data_test, label_test, cv=5)\n",
        "    precision = cross_val_score(model, data_test, label_test, cv=5, scoring=precision_scorer)\n",
        "    recall = cross_val_score(model, data_test, label_test, cv=5, scoring=recall_scorer)\n",
        "    f1_score_result = cross_val_score(model, data_test, label_test, cv=5, scoring=f1_scorer)\n",
        "\n",
        "    print(\"Accuracy of cross validated logistic regression : %0.2f (+/- %0.2f)\" % (acuuracy.mean(), acuuracy.std() * 2))\n",
        "    print(\"Precision of cross validated logistic regression : %0.2f (+/- %0.2f)\" % (precision.mean(), precision.std() * 2))\n",
        "    print(\"Recall of cross validated logistic regression : %0.2f (+/- %0.2f)\" % (recall.mean(), recall.std() * 2))\n",
        "    print(\"F1-Score of cross validated logistic regression : %0.2f (+/- %0.2f)\" % (f1_score_result.mean(), f1_score_result.std() * 2))\n",
        "    \n",
        "\n",
        "def predictLogisticalRegression(dataframe, corpusText, labelText, splitPercentage, classifier, description, ngrams, runCoeffecient = True):\n",
        "    # differentiate the data for train and test sets \n",
        "    train_corpus, test_corpus, train_labels, test_labels = prepare_datasets(dataframe[corpusText],\n",
        "                                                                                dataframe[labelText],\n",
        "                                                                                test_data_proportion=splitPercentage)\n",
        "    \n",
        "    tfidf_vectorizer, tfidf_train_features = tfidf_extractor(train_corpus, ngrams)  \n",
        "    tfidf_test_features = tfidf_vectorizer.transform(test_corpus)\n",
        "    \n",
        "    \n",
        "    \n",
        "    # bag of words transformation \n",
        "    tfidf_vectorizer, tfidf_feature = tfidf_extractor(data[corpusText])\n",
        "    \n",
        "    tfidf_predictions = train_predict_evaluate_model(classifier=classifier,\n",
        "                                                       train_features=tfidf_train_features,\n",
        "                                                       train_labels=train_labels,\n",
        "                                                       test_features=tfidf_test_features,\n",
        "                                                       test_labels=test_labels,\n",
        "                                                        text = description)\n",
        "    \n",
        "    print_cross_validation_model_measurements(classifier, tfidf_feature, data[labelText])\n",
        "    \n",
        "    cm = getConfussionMatrix(test_labels, tfidf_predictions, description) \n",
        "    \n",
        "    if runCoeffecient :\n",
        "        getCoeeffienct(classifier, tfidf_vectorizer, description)\n",
        "    \n",
        "    \n",
        "tfidf_model = LogisticRegression(random_state=0, solver='lbfgs', max_iter = 1000)\n",
        "\n",
        "predictLogisticalRegression(data, \"FullText\", \"IsHateSpeech\", 0.2, tfidf_model,  \"Full data set\", (1,1))\n",
        "\n",
        "\n",
        "#need to do pipeline "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "------------------------Model metrice for Full data set------------------------\nAccuracy: 0.67\nPrecision: 0.68\nRecall: 0.67\nF1 Score: 0.65\nAccuracy of cross validated logistic regression : 0.65 (+/- 0.10)\nPrecision of cross validated logistic regression : 0.68 (+/- 0.16)\nRecall of cross validated logistic regression : 0.39 (+/- 0.20)\nF1-Score of cross validated logistic regression : 0.49 (+/- 0.21)\n------------------------Confussion metrice for Full data set------------------------\n                     Prediction    \n                 P     |    N   \n              ---------|---------\n               P 229       43   \n    Actual   ----------|---------\n               N 123       105   \n                       | \n------------------------Most important words the model for Full data set  ------------------------\n   උපක\n   ජනයක\n   උපද\n   එවනව\n   කවරණය\n   උඹලග\n   wunu\n   wedagthm\n   thunema\n   එකල\n   lassanaimn\n   yaddi\n   ගහ\n   wagema\n   tota\n   ඉල\n   නයකට\n   කඩනව\n   එකඟව\n   lassani\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "### Part F\n",
        "\n",
        "1. considering context words by building a bag-of-n-grams model "
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "# run the same logistical regession model with more ngrams \n",
        "predictLogisticalRegression(data, \"FullText\", \"IsHateSpeech\", 0.2, tfidf_model,  \"Full data set\", (1,3), False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "------------------------Model metrice for Full data set------------------------\nAccuracy: 0.65\nPrecision: 0.66\nRecall: 0.65\nF1 Score: 0.64\nAccuracy of cross validated logistic regression : 0.65 (+/- 0.10)\nPrecision of cross validated logistic regression : 0.68 (+/- 0.16)\nRecall of cross validated logistic regression : 0.39 (+/- 0.20)\nF1-Score of cross validated logistic regression : 0.49 (+/- 0.21)\n------------------------Confussion metrice for Full data set------------------------\n                     Prediction    \n                 P     |    N   \n              ---------|---------\n               P 228       44   \n    Actual   ----------|---------\n               N 130       98   \n                       | \n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "### Part F\n",
        "\n",
        "2. using semantic embeddings instead of bag-of-word vectors for word representation to model the data. \n",
        "3. Output the performance of the model you create from each of the above in the most meaningful way and comment on the predictive power of the model."
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "import numpy as np    \n",
        "\n",
        "def average_word_vectors(words, model, vocabulary, num_features):\n",
        "    \n",
        "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
        "    nwords = 0.\n",
        "    \n",
        "    for word in words:\n",
        "        if word in vocabulary: \n",
        "            nwords = nwords + 1.\n",
        "            feature_vector = np.add(feature_vector, model[word])\n",
        "    \n",
        "    if nwords:\n",
        "        feature_vector = np.divide(feature_vector, nwords)\n",
        "        \n",
        "    return feature_vector\n",
        "\n",
        "def averaged_word_vectorizer(corpus, model, num_features):\n",
        "    vocabulary = set(model.wv.index2word)\n",
        "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
        "                    for tokenized_sentence in corpus]\n",
        "    return np.array(features)\n",
        "\n",
        "\n",
        "def tfidf_wtd_avg_word_vectors(words, tfidf_vector, tfidf_vocabulary, model, num_features):\n",
        "    \n",
        "    word_tfidfs = [tfidf_vector[0, tfidf_vocabulary.get(word)] \n",
        "                   if tfidf_vocabulary.get(word) \n",
        "                   else 0 for word in words]    \n",
        "    word_tfidf_map = {word:tfidf_val for word, tfidf_val in zip(words, word_tfidfs)}\n",
        "    \n",
        "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
        "    vocabulary = set(model.wv.index2word)\n",
        "    wts = 0.\n",
        "    for word in words:\n",
        "        if word in vocabulary: \n",
        "            word_vector = model[word]\n",
        "            weighted_word_vector = word_tfidf_map[word] * word_vector\n",
        "            wts = wts + word_tfidf_map[word]\n",
        "            feature_vector = np.add(feature_vector, weighted_word_vector)\n",
        "    if wts:\n",
        "        feature_vector = np.divide(feature_vector, wts)\n",
        "        \n",
        "    return feature_vector\n",
        "\n",
        "def tfidf_weighted_averaged_word_vectorizer(corpus, tfidf_vectors, \n",
        "                                   tfidf_vocabulary, model, num_features):\n",
        "                                       \n",
        "    docs_tfidfs = [(doc, doc_tfidf) \n",
        "                   for doc, doc_tfidf \n",
        "                   in zip(corpus, tfidf_vectors)]\n",
        "    features = [tfidf_wtd_avg_word_vectors(tokenized_sentence, tfidf, tfidf_vocabulary,\n",
        "                                   model, num_features)\n",
        "                    for tokenized_sentence, tfidf in docs_tfidfs]\n",
        "    return np.array(features) \n",
        "\n",
        "\n",
        "def predictLogisticalRegressionWithWord2Vec(dataframe, corpusText, labelText, splitPercentage, description, ngrams, runCoeffecient = True):\n",
        "    \n",
        "    svm = SGDClassifier(loss='hinge', max_iter = 100)\n",
        "    \n",
        "    # differentiate the data for train and test sets \n",
        "    train_corpus, test_corpus, train_labels, test_labels = prepare_datasets(dataframe[corpusText],\n",
        "                                                                                dataframe[labelText],\n",
        "                                                                                test_data_proportion=splitPercentage)\n",
        "    \n",
        "    # tokenize documents\n",
        "    tokenized_train = [nltk.word_tokenize(text)\n",
        "                       for text in train_corpus]\n",
        "    tokenized_test = [nltk.word_tokenize(text)\n",
        "                       for text in test_corpus]\n",
        "    \n",
        "    model = gensim.models.Word2Vec(tokenized_train,\n",
        "                               size=500,\n",
        "                               window=100,\n",
        "                               min_count=30,\n",
        "                               sample=1e-3)\n",
        "    \n",
        "    tfidf_vectorizer, tfidf_train_features = tfidf_extractor(train_corpus, ngrams)  \n",
        "    tfidf_test_features = tfidf_vectorizer.transform(test_corpus)\n",
        "    \n",
        "    # averaged word vector features\n",
        "    avg_wv_train_features = averaged_word_vectorizer(corpus=tokenized_train,\n",
        "                                                     model=model.wv,\n",
        "                                                     num_features=500)                   \n",
        "    avg_wv_test_features = averaged_word_vectorizer(corpus=tokenized_test,\n",
        "                                                    model=model.wv,\n",
        "                                                    num_features=500)                                                 \n",
        "\n",
        "\n",
        "\n",
        "    # tfidf weighted averaged word vector features\n",
        "    vocab = tfidf_vectorizer.vocabulary_\n",
        "    tfidf_wv_train_features = tfidf_weighted_averaged_word_vectorizer(corpus=tokenized_train, \n",
        "                                                                      tfidf_vectors=tfidf_train_features, \n",
        "                                                                      tfidf_vocabulary=vocab, \n",
        "                                                                      model=model, \n",
        "                                                                      num_features=500)\n",
        "    \n",
        "    \n",
        "    tfidf_wv_test_features = tfidf_weighted_averaged_word_vectorizer(corpus=tokenized_test, \n",
        "                                                                     tfidf_vectors=tfidf_test_features, \n",
        "                                                                     tfidf_vocabulary=vocab, \n",
        "                                                                     model=model, \n",
        "                                                                     num_features=500)\n",
        "    \n",
        "    \n",
        "    \n",
        "    description = \"SVM with ngrams and averaged vector features\"\n",
        "    \n",
        "    # Support Vector Machine with averaged word vector features\n",
        "    svm_avgwv_predictions = train_predict_evaluate_model(classifier=svm,\n",
        "                                               train_features=avg_wv_train_features,\n",
        "                                               train_labels=train_labels,\n",
        "                                               test_features=avg_wv_test_features,\n",
        "                                               test_labels=test_labels,\n",
        "                                                text = description)\n",
        "    \n",
        "    # cross validation error \n",
        "    #print_cross_validation_model_measurements(svm, svm_avgwv_predictions, test_labels)\n",
        "    \n",
        "    \n",
        "    \n",
        "    if runCoeffecient :\n",
        "        cm = getConfussionMatrix(test_labels, svm_avgwv_predictions, description) \n",
        "        getCoeeffienct(svm, tfidf_vectorizer, description)\n",
        "    \n",
        "    \n",
        "    description = \"SVM with ngrams and tfid weigted word vector features\"\n",
        "    \n",
        "    # Support Vector Machine with tfidf weighted averaged word vector features\n",
        "    svm_tfidfwv_predictions = train_predict_evaluate_model(classifier=svm,\n",
        "                                               train_features=tfidf_wv_train_features,\n",
        "                                               train_labels=train_labels,\n",
        "                                               test_features=tfidf_wv_test_features,\n",
        "                                               test_labels=test_labels,\n",
        "                                                text = description)\n",
        "    \n",
        "    \n",
        "    # cross validation error \n",
        "    #print_cross_validation_model_measurements(svm, svm_tfidfwv_predictions, test_labels)\n",
        "    \n",
        "    \n",
        "    \n",
        "    if runCoeffecient :\n",
        "        cm = getConfussionMatrix(test_labels, svm_tfidfwv_predictions, description) \n",
        "        getCoeeffienct(svm, tfidf_vectorizer, description)\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "#data['IsHateSpeechNumeric'] = data.apply(lambda row: 1 if row.IsHateSpeech == \"YES\" else 0 , axis=1)\n",
        "        \n",
        "# run the same logistical regession model with more ngrams \n",
        "predictLogisticalRegressionWithWord2Vec(data, \"FullText\", \"IsHateSpeech\", 0.2,  \"Full data set\", (1,3), False)\n",
        "\n",
        "\n",
        "#https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "------------------------Model metrice for SVM with ngrams and averaged vector features------------------------\nAccuracy: 0.54\nPrecision: 0.3\nRecall: 0.54\nF1 Score: 0.38\n------------------------Model metrice for SVM with ngrams and tfid weigted word vector features------------------------\nAccuracy: 0.54\nPrecision: 0.3\nRecall: 0.54\nF1 Score: 0.38\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": [
        "## Part G\n",
        "\n",
        "1. First we implement the smae data set using all 3 methods (Naive Bayse, Lininer Model and Loagistic Regression)\n"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X = data['FullText'].values.tolist()\n",
        "y = data['IsHateSpeech'].values.tolist()\n",
        "tags = ['YES', 'NO']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "### Naive Bayse"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "nb = Pipeline([('vect', CountVectorizer()),\n",
        "               ('tfidf', TfidfTransformer()),\n",
        "               ('clf', MultinomialNB()),\n",
        "              ])\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "y_pred = nb.predict(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=tags))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "accuracy 0.69\n              precision    recall  f1-score   support\n\n         YES       0.66      0.91      0.76       272\n          NO       0.80      0.43      0.56       228\n\n   micro avg       0.69      0.69      0.69       500\n   macro avg       0.73      0.67      0.66       500\nweighted avg       0.72      0.69      0.67       500\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "### Linnier Regression"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
        "               ])\n",
        "sgd.fit(X_train, y_train)\n",
        "\n",
        "y_pred = sgd.predict(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=tags))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "accuracy 0.674\n              precision    recall  f1-score   support\n\n         YES       0.64      0.89      0.75       272\n          NO       0.76      0.41      0.54       228\n\n   micro avg       0.67      0.67      0.67       500\n   macro avg       0.70      0.65      0.64       500\nweighted avg       0.70      0.67      0.65       500\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "### Logistical Rgression"
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
        "               ])\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
        "print(classification_report(y_test, y_pred,target_names=tags))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "accuracy 0.648\n              precision    recall  f1-score   support\n\n         YES       0.66      0.72      0.69       272\n          NO       0.63      0.57      0.59       228\n\n   micro avg       0.65      0.65      0.65       500\n   macro avg       0.64      0.64      0.64       500\nweighted avg       0.65      0.65      0.65       500\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "### Part G evaluation "
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "The individual results where almost smae with acuraccy values when there were run sepratly with different functionalities . From the above result we can eveluate that Naive Bayse gave the best result for the data set. There would be less overfitting as the results predicated for test sets where not everly high values. \n",
        "\n",
        "Finally in case of sinhala hate speech we would have to implement more models with corpuses whihc had spelling mistakes fixed .  Additonally as there is not a propper way of defining singlish words we coul have to create corpuses which defines sinhala word eqvanlt in singlish word so that we could finally convert the singlish word to shinhala and then  run the full predictions whihc would help provide better results in Hate speach identification .  "
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python37864bit858f2d248df842109f5668a2b2ef8247",
      "display_name": "Python 3.7.8 64-bit",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8-final",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}